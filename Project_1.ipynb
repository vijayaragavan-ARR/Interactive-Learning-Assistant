{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "yBJR8I3TLZaD",
        "outputId": "18ab9e79-f310-4a67-9e38-f68efc2629be"
      },
      "outputs": [],
      "source": [
        "# IMPORT NECESSARY LIBRARIES AND MODULES\n",
        "import os\n",
        "import pickle\n",
        "import pytesseract\n",
        "from PyPDF2 import PdfReader,PdfMerger\n",
        "from langchain.llms import Replicate,GooglePalm\n",
        "from langchain.chains import LLMChain\n",
        "from pdf2image import convert_from_path\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import WebBaseLoader, YoutubeLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W92HQpHIPbs1",
        "outputId": "260009c3-570b-4016-c298-ad82b2952073"
      },
      "outputs": [],
      "source": [
        "# SET UP REPLICATE API TOKEN\n",
        "REPLICATE_API_TOKEN = \"r8_UCIhBwlSzDR0vftGFySLx510Xv5af831qFfB3\"\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SET UP REPLICATE MODEL\n",
        "llm = Replicate(\n",
        "      model=\"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
        "      model_kwargs={\n",
        "          \"temperature\": 0.5,\n",
        "          \"max_length\": 1000,\n",
        "          \"top_p\": 1,\n",
        "          \"system_prompt\":\"You are an adaptive learning assistant designed to provide innovative and specific answers to learners. Your responses should be concise, avoiding unnecessary questions. Prioritize accuracy and educational value.If faced with an unclear or incoherent question, guide the user to clarity rather than providing inaccurate information. If uncertain about an answer, refrain from sharing misinformation. AND STOP AFTER ANSWERING THE QUESTION. BE SPECIFIC AND CONCISE.\"},\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTION TO LOAD CONTENT FROM WEB AND YOUTUBE\n",
        "def load_URL():\n",
        "    website_url = input(\"Web URL: \")\n",
        "    web_loader = WebBaseLoader(website_url)\n",
        "    web_docs = web_loader.load()\n",
        "\n",
        "    youtube_url = input(\"YouTube URL: \")\n",
        "    yt_loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=True)\n",
        "    yt_docs = yt_loader.load()\n",
        "    return web_docs + yt_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTION TO EXTRACT TEXT FROM DOCUMENTS\n",
        "def extract_text(docs):\n",
        "    return ''.join(doc.page_content for doc in docs)\n",
        "\n",
        "# FUNCTION TO LOAD PDF AND EXTRACT TEXT\n",
        "def load_pdf(pdf_path):\n",
        "    pdf=PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in pdf.pages:\n",
        "        text += page.extract_text()\n",
        "    if not text:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        text = ' '.join([pytesseract.image_to_string(image) for image in images])\n",
        "    return text\n",
        "\n",
        "# FUNCTION TO COMBINE PDFs FROM A DIRECTORY\n",
        "def combine_pdfs(directory_path, output_path='combined_pdf.pdf'):\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"No PDF files found in the specified directory.\")\n",
        "        return\n",
        "\n",
        "    pdf_merger = PdfMerger()\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(directory_path, pdf_file)\n",
        "        pdf_merger.append(pdf_path)\n",
        "\n",
        "    pdf_merger.write(output_path)\n",
        "    pdf_merger.close()\n",
        "\n",
        "    print(f\"Combined PDF saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined PDF saved to: combined_pdf.pdf\n"
          ]
        }
      ],
      "source": [
        "# MAIN PDF DIRECTORY\n",
        "pdf_directory_path = 'PDF'\n",
        "combine_pdfs(pdf_directory_path)\n",
        "\n",
        "# LOAD COMBINED PDF AND EXTRACT TEXT\n",
        "pdf_path_combined = 'combined_pdf.pdf'\n",
        "text = load_pdf(pdf_path_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ASK USER IF THEY WANT TO USE WEBSITE AND YOUTUBE CONTENT\n",
        "webyt = input(\"Do you want to use website and YouTube content? (yes or no): \").capitalize()\n",
        "llm1 = GooglePalm(google_api_key=\"AIzaSyB5xjvlZYxPJso_ahyJaeDh3DE2RX22gl4\", temparature=0.7)\n",
        "# IF YES, LOAD CONTENT FROM WEB AND YOUTUBE\n",
        "if webyt == 'Yes':\n",
        "    docs=load_URL()\n",
        "    text += extract_text(docs)\n",
        "\n",
        "# SPLIT TEXT INTO CHUNKS FOR PROCESSING\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "chunk_size=2000,\n",
        "chunk_overlap=250,\n",
        "length_function=len\n",
        ")\n",
        "chunks=text_splitter.split_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "22yenhvXLli2"
      },
      "outputs": [],
      "source": [
        "# SET UP VECTORSTORE FOR STORING EMBEDDINGS\n",
        "store_name =\"UPDATE\"\n",
        "if os.path.exists(f\"{store_name}.pkl\"):\n",
        "            with open(f\"{store_name}.pkl\", \"rb\") as f:\n",
        "                VectorStore = pickle.load(f)\n",
        "else:\n",
        "    embeddings = HuggingFaceInstructEmbeddings()\n",
        "    VectorStore = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "    \n",
        "    with open(f\"{store_name}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(VectorStore, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD QUESTION-ANSWERING CHAIN\n",
        "chain = load_qa_chain(llm=llm, chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTION TO OPTIMIZE THE GENERATED RESPONSE\n",
        "def opti_response(response):\n",
        "    if '\\\\'in response:\n",
        "        response = response.split('\\\\')[0]\n",
        "    elif '?'in response:\n",
        "        response = response.split('?')[0]\n",
        "    elif '/' in response:\n",
        "        response = response.split('/')[0]\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTION TO GENERATE A RESPONSE TO A USER QUERY\n",
        "def ResponseQuery(query):\n",
        "  if not query:\n",
        "    return \"I don't have a response for an empty query.\"\n",
        "  docs = VectorStore.similarity_search(query=query, k=3)\n",
        "  response = opti_response(chain.run(input_documents=docs, question=query))\n",
        "  return response\n",
        "\n",
        "# FUNCTION TO EVALUATE USER-PROVIDED ANSWERS\n",
        "def evaluate_ans(ans1, ans2, query):\n",
        "    eval_temp = \"\"\"\n",
        "    Given 2 different responses ({ans1}) and ({ans2}) to a ({query}), name the first response as AI-Answer and the second response as USER-Answer. Evaluate the responses based on the following criteria:\n",
        "\n",
        "    1. Relevance: Assess the relevance of the content to the given context. Ensure that the response directly addresses the specified rules and requirements.\n",
        "    2. Completeness: Verify if the response covers all the specified points and includes all necessary information.\n",
        "    3. Grammar and Clarity: Check for grammatical errors and assess the overall clarity of the response.\n",
        "    4. Improvement Suggestions: Provide constructive feedback on how the response could be improved, suggesting specific areas for enhancement or clarification.\n",
        "    5. Overall Rating out of 10: Assign a numerical score to the response based on the overall quality, considering accuracy, relevance, creativity, completeness, and clarity.\n",
        "\n",
        "    Note: Please avoid using symbols like '*' in your responses.\n",
        "    \"\"\"\n",
        "\n",
        "    evaluation_template = PromptTemplate(input_variables=[\"ans1\", \"ans2\", \"query\"], template=eval_temp)\n",
        "    evaluation_template.format(ans1=ans1, ans2=ans2, query=query)\n",
        "    llm_chain = LLMChain(llm=llm, prompt=evaluation_template)\n",
        "    print(\"AI-ANS: \",ans1,end=\"\\n\\n\")\n",
        "    print(llm_chain.run({\"ans1\": ans1, \"ans2\": ans2, \"query\": query}),end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9oQIZC-60Ug_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Sure! Here's a question for you:\n",
            "\n",
            "What are some potential benefits and drawbacks of using chatbots as a language learning medium, and how can they be optimized for effective language learning experiences\n",
            "Your answer:  none\n",
            "AI-ANS:   Benefits of using chatbots as a language learning medium include:\n",
            "\n",
            "1. Personalized interaction: Chatbots can provide learners with personalized interactions that simulate human conversation, allowing them to practice their language skills in a more realistic way.\n",
            "2. Accessibility: Chatbots can be accessed at any time and from any location, making them a convenient option for language learners who may not have access to traditional language classes or tutors.\n",
            "3. Cost-effective: Chatbots can reduce the cost of language learning, as they do not require the same level of human\n",
            "\n",
            " AI-Answer:\n",
            "\n",
            "Benefits of using chatbots as a language learning medium include:\n",
            "\n",
            "1. Personalized interaction: Chatbots can provide learners with personalized interactions that simulate human conversation, allowing them to practice their language skills in a more realistic way.\n",
            "2. Accessibility: Chatbots can be accessed at any time and from any location, making them a convenient option for language learners who may not have access to traditional language classes or tutors.\n",
            "3. Cost-effective: Chatbots can reduce the cost of language learning, as they do\n",
            "\n",
            "Multiple choice Question: \n",
            " Sure! Here's a multiple choice question for you:\n",
            "\n",
            "Which of the following is NOT a component of the Langchain Framework\n",
            "Your Answer:  i don't know\n"
          ]
        }
      ],
      "source": [
        "#MAIN FUNCTION:\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        user_input = input(\"ask a question or answer a question: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"Multiple choice Question: \")\n",
        "            response=ResponseQuery(\"Ask me a multiple choice question with 4 choices:\")\n",
        "            print(response)\n",
        "            human_ans = input(f' give me your answer for \"{response}\": ')\n",
        "            print('Your Answer: ', human_ans)\n",
        "            print('Correct Answer: ',ResponseQuery(response))\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        if user_input.lower() == \"ask\":\n",
        "            query = \"Ask me a question.\"\n",
        "            response = ResponseQuery(query)\n",
        "            print(response)\n",
        "            human_ans = input(f' give me your answer for \"{response}\": ')\n",
        "            print('Your answer: ', human_ans)\n",
        "            evaluate_ans(ResponseQuery(response), human_ans, response)\n",
        "        else:\n",
        "            query = input(\"Ask questions about your PDF file:\")\n",
        "            response = ResponseQuery(query)\n",
        "            print(\"QUESTION:\", query,end=\"\\n\\n\")\n",
        "            print(\"ANSWER:\", response, sep=\" \", end=\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
